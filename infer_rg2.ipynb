{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 读文件\n",
    "- 1.休息西\n",
    "### 传入模型出热图\n",
    "### 保存结果 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn    as nn\n",
    "\n",
    "import h5py as h5\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "cur_path = os.path.abspath(\".\")\n",
    "data_path = os.path.join(cur_path,'data')\n",
    "print(f\"cur_path:{cur_path}\")\n",
    "print(f\"data_path:{data_path}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cur_path:/home/xindong/project/rg2-work\n",
      "data_path:/home/xindong/project/rg2-work/data\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "img = sitk.ReadImage(os.path.join(data_path,'image006.nii.gz'))\n",
    "print(img.GetSize())\n",
    "xray_data = sitk.GetArrayFromImage(img)\n",
    "\n",
    "print(type(xray_data),xray_data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1536, 1536)\n",
      "<class 'numpy.ndarray'> (1536, 1536)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(xray_data[:,:],cmap='gray')\n",
    "plt.show"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "metadata": {},
     "execution_count": 100
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# General utility functions\n",
    "#\n",
    "# Copyright (C) 2019-2020 Robert Grupp (grupp@jhu.edu)\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program. If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dice import *\n",
    "\n",
    "def get_gaussian_2d_heatmap(num_rows, num_cols, sigma, peak_row=None, peak_col=None):\n",
    "    if peak_row is None:\n",
    "        peak_row = num_rows // 2\n",
    "    if peak_col is None:\n",
    "        peak_col = num_cols // 2\n",
    "    \n",
    "    (Y,X) = torch.meshgrid(torch.arange(0,num_rows), torch.arange(0,num_cols))\n",
    "    \n",
    "    Y = Y.float()\n",
    "    X = X.float()\n",
    "\n",
    "    return torch.exp(((X - peak_col).pow(2) + (Y - peak_row).pow(2)) / (sigma * sigma * -2)) / (2 * math.pi * sigma * sigma)\n",
    "\n",
    "def write_floats_to_txt(file_path, floats):\n",
    "    with open(file_path,'w') as out:\n",
    "        for f in floats:\n",
    "            out.write('{:.6f}\\n'.format(f))\n",
    "        out.flush()\n",
    "\n",
    "def read_floats_from_txt(file_path):\n",
    "    return torch.Tensor([float(l.strip()) for l in open(file_path).readlines()])\n",
    "\n",
    "class RunningFloatWriter:\n",
    "    def __init__(self, file_path, new_file=True):\n",
    "        super(RunningFloatWriter,self).__init__()\n",
    "\n",
    "        write_mode = 'w'\n",
    "        if not new_file:\n",
    "            write_mode = 'a'\n",
    "\n",
    "        self.out = open(file_path, write_mode)\n",
    "\n",
    "    def write(self, x):\n",
    "        self.out.write('{:.6f}\\n'.format(x))\n",
    "        self.out.flush()\n",
    "\n",
    "    def close(self):\n",
    "        if self.out:\n",
    "            self.out.flush()\n",
    "            self.out.close()\n",
    "            self.out = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "\n",
    "def center_crop(img, dst_shape):\n",
    "    src_nr = img.shape[-2]\n",
    "    src_nc = img.shape[-1]\n",
    "\n",
    "    dst_nr = dst_shape[-2]\n",
    "    dst_nc = dst_shape[-1]\n",
    "    \n",
    "    if (dst_nr != src_nr) or (dst_nc != src_nc):\n",
    "        src_start_r = int((src_nr - dst_nr) / 2)\n",
    "        src_end_r   = src_start_r + dst_nr\n",
    "        \n",
    "        src_start_c = int((src_nc - dst_nc) / 2)\n",
    "        src_end_c   = src_start_c + dst_nc\n",
    "        \n",
    "        if img.dim() == 4:\n",
    "            return img[:,:,src_start_r:src_end_r,src_start_c:src_end_c]\n",
    "        elif img.dim() == 3:\n",
    "            return img[:,src_start_r:src_end_r,src_start_c:src_end_c]\n",
    "        else:\n",
    "            assert(img.dim() == 2)\n",
    "            return img[src_start_r:src_end_r,src_start_c:src_end_c]\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def test_dataset(ds, net, dev=None, num_lands=0):\n",
    "    dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "\n",
    "        losses = torch.zeros(len(ds))\n",
    "        \n",
    "        num_items = 0\n",
    "    \n",
    "        if num_lands > 0:\n",
    "            criterion = DiceAndHeatMapLoss2D(skip_bg=False)\n",
    "        else:\n",
    "            criterion = DiceLoss2D(skip_bg=False)\n",
    "\n",
    "        for (i, data) in enumerate(dl, 0):\n",
    "            (projs, masks, lands, heats) = data\n",
    "            \n",
    "            if dev is not None:\n",
    "                projs = projs.to(dev)\n",
    "                masks = masks.to(dev)\n",
    "                if num_lands > 0:\n",
    "                    if len(heats.shape) > 4:\n",
    "                        assert(len(heats.shape) == 5)\n",
    "                        assert(heats.shape[2] == 1)\n",
    "                        heats = heats.view(heats.shape[0], heats.shape[1], heats.shape[3], heats.shape[4])\n",
    "                    heats = heats.to(dev)\n",
    "\n",
    "            net_out = net(projs)\n",
    "            if (num_lands > 0) or (type(net_out) is tuple):\n",
    "                pred_masks     = net_out[0]\n",
    "                pred_heat_maps = net_out[1]\n",
    "            else:\n",
    "                pred_masks = net_out\n",
    "\n",
    "            pred_masks = center_crop(pred_masks, masks.shape)\n",
    "            \n",
    "            if num_lands > 0:\n",
    "                pred_heat_maps = center_crop(pred_heat_maps, heats.shape)\n",
    "                loss = criterion((pred_masks, pred_heat_maps), (masks, heats))\n",
    "            else:\n",
    "                loss = criterion(pred_masks, masks)\n",
    "\n",
    "            losses[i] = loss.item()\n",
    "\n",
    "            num_items += 1\n",
    "        \n",
    "        assert(num_items == len(ds))\n",
    "\n",
    "        return (torch.mean(losses), torch.std(losses))\n",
    "\n",
    "def test_dataset_ensemble(ds, nets, dev=None, num_lands=0, dice_only=False):\n",
    "    num_nets = len(nets)\n",
    "\n",
    "    dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for net in nets:\n",
    "            net.eval()\n",
    "\n",
    "        losses = torch.zeros(len(ds))\n",
    "        \n",
    "        num_items = 0\n",
    "    \n",
    "        if not dice_only and (num_lands > 0):\n",
    "            criterion = DiceAndHeatMapLoss2D(skip_bg=False)\n",
    "        else:\n",
    "            criterion = DiceLoss2D(skip_bg=False)\n",
    "\n",
    "        for (i, data) in enumerate(dl, 0):\n",
    "            (projs, masks, lands, heats) = data\n",
    "            \n",
    "            if dev is not None:\n",
    "                projs = projs.to(dev)\n",
    "                masks = masks.to(dev)\n",
    "                if num_lands > 0:\n",
    "                    if len(heats.shape) > 4:\n",
    "                        assert(len(heats.shape) == 5)\n",
    "                        assert(heats.shape[2] == 1)\n",
    "                        heats = heats.view(heats.shape[0], heats.shape[1], heats.shape[3], heats.shape[4])\n",
    "                    heats = heats.to(dev)\n",
    "\n",
    "            avg_masks = None\n",
    "            avg_heats = None\n",
    "\n",
    "            for net in nets:\n",
    "                net_out = net(projs)\n",
    "                if (num_lands > 0) or (type(net_out) is tuple):\n",
    "                    pred_masks     = net_out[0]\n",
    "                    pred_heat_maps = net_out[1]\n",
    "                else:\n",
    "                    pred_masks = net_out\n",
    "\n",
    "                pred_masks = center_crop(pred_masks, masks.shape)\n",
    "\n",
    "                if avg_masks is None:\n",
    "                    avg_masks = pred_masks\n",
    "                else:\n",
    "                    avg_masks += pred_masks\n",
    "            \n",
    "                if num_lands > 0:\n",
    "                    pred_heat_maps = center_crop(pred_heat_maps, heats.shape)\n",
    "\n",
    "                    if avg_heats is None:\n",
    "                        avg_heats = pred_heat_maps\n",
    "                    else:\n",
    "                        avg_heats += pred_heat_maps\n",
    "            # end for net\n",
    "            \n",
    "            avg_masks /= num_nets\n",
    "\n",
    "            if num_lands > 0:\n",
    "                avg_heats /= num_nets\n",
    "\n",
    "            if not dice_only and (num_lands > 0):\n",
    "                loss = criterion((avg_masks, avg_heats), (masks, heats))\n",
    "            else:\n",
    "                loss = criterion(avg_masks, masks)\n",
    "\n",
    "            losses[i] = loss.item()\n",
    "\n",
    "            num_items += 1\n",
    "        \n",
    "        assert(num_items == len(ds))\n",
    "\n",
    "        return (torch.mean(losses), torch.std(losses))\n",
    "\n",
    "def seg_dataset(ds, net, h5_f, dev=None, num_lands=0):\n",
    "    orig_img_shape = ds.rob_orig_img_shape\n",
    "    \n",
    "    dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "   \n",
    "    dst_ds = h5_f.create_dataset('nn-segs', (len(ds), *orig_img_shape),\n",
    "                                 dtype='u1',\n",
    "                                 chunks=(1, *orig_img_shape),\n",
    "                                 compression=\"gzip\", compression_opts=9)\n",
    "    \n",
    "    dst_heats_ds = None\n",
    "\n",
    "    if num_lands > 0:\n",
    "        dst_heats_ds = h5_f.create_dataset('nn-heats', (len(ds), num_lands, *orig_img_shape),\n",
    "                                           chunks=(1,1,*orig_img_shape),\n",
    "                                           compression=\"gzip\", compression_opts=9)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "\n",
    "        num_items = 0\n",
    "        \n",
    "        for (i, data) in enumerate(dl, 0):\n",
    "            projs = data[0]\n",
    "\n",
    "            if dev is not None:\n",
    "                projs = projs.to(dev)\n",
    "\n",
    "            net_out = net(projs)\n",
    "            if (num_lands > 0) or (type(net_out) is tuple):\n",
    "                pred_masks = net_out[0]\n",
    "                pred_heats = net_out[1]\n",
    "            else:\n",
    "                pred_masks = net_out\n",
    "\n",
    "            pred_masks = center_crop(pred_masks, orig_img_shape)\n",
    "\n",
    "            (_, pred_masks) = torch.max(pred_masks, dim=1)\n",
    "   \n",
    "            # write to file\n",
    "            dst_ds[i,:,:] = pred_masks.view(orig_img_shape).cpu().numpy()\n",
    "\n",
    "            if dst_heats_ds is not None:\n",
    "                dst_heats_ds[i,:,:,:] = center_crop(pred_heats, orig_img_shape).numpy()\n",
    "\n",
    "            num_items += 1\n",
    "        \n",
    "        assert(num_items == len(ds))\n",
    "\n",
    "\n",
    "def seg_dataset_ensemble(ds, nets, h5_f, dev=None, num_lands=0, times=None):\n",
    "    num_nets = len(nets)\n",
    "\n",
    "    orig_img_shape = ds.rob_orig_img_shape\n",
    "    \n",
    "    dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "   \n",
    "    dst_ds = h5_f.create_dataset('nn-segs', (len(ds), *orig_img_shape),\n",
    "                                 dtype='u1',\n",
    "                                 chunks=(1, *orig_img_shape),\n",
    "                                 compression=\"gzip\", compression_opts=9)\n",
    "    \n",
    "    dst_heats_ds = None\n",
    "\n",
    "    if num_lands > 0:\n",
    "        dst_heats_ds = h5_f.create_dataset('nn-heats', (len(ds), num_lands, *orig_img_shape),\n",
    "                                           chunks=(1,1,*orig_img_shape),\n",
    "                                           compression=\"gzip\", compression_opts=9)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for net in nets:\n",
    "            net.eval()\n",
    "\n",
    "        num_items = 0\n",
    "        \n",
    "        for (i, data) in enumerate(dl, 0):\n",
    "            projs = data[0]\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            if dev is not None:\n",
    "                projs = projs.to(dev)\n",
    "\n",
    "            avg_masks = None\n",
    "            \n",
    "            avg_heats = None\n",
    "\n",
    "            for net in nets:\n",
    "                net_out = net(projs)\n",
    "                if (num_lands > 0) or (type(net_out) is tuple):\n",
    "                    pred_masks = net_out[0]\n",
    "                    pred_heats = net_out[1]\n",
    "                else:\n",
    "                    pred_masks = net_out\n",
    "\n",
    "                pred_masks = center_crop(pred_masks, orig_img_shape)\n",
    "\n",
    "                if avg_masks is None:\n",
    "                    avg_masks = pred_masks\n",
    "                else:\n",
    "                    avg_masks += pred_masks\n",
    "            \n",
    "                if dst_heats_ds is not None:\n",
    "                    pred_heats = center_crop(pred_heats, orig_img_shape)\n",
    "                    \n",
    "                    pred_heats_min = pred_heats.min().item()\n",
    "                    pred_heats_max = pred_heats.max().item()\n",
    "                    \n",
    "                    pred_heats = (pred_heats - pred_heats_min) / (pred_heats_max - pred_heats_min)\n",
    "\n",
    "                    if avg_heats is None:\n",
    "                        avg_heats = pred_heats\n",
    "                    else:\n",
    "                        avg_heats += pred_heats\n",
    "            \n",
    "            # technically we don't need to do this for the segmentation\n",
    "            avg_masks /= num_nets\n",
    "\n",
    "            (_, pred_masks) = torch.max(avg_masks, dim=1)\n",
    "            \n",
    "            stop_time = time.time()\n",
    "\n",
    "            if times is not None:\n",
    "                times.append(stop_time - start_time)\n",
    "\n",
    "            # write to file\n",
    "            dst_ds[i,:,:] = pred_masks.view(orig_img_shape).cpu().numpy()\n",
    "            \n",
    "            if dst_heats_ds is not None:\n",
    "                avg_heats /= num_nets\n",
    "                dst_heats_ds[i,:,:,:] = avg_heats.cpu().numpy()\n",
    "\n",
    "            num_items += 1\n",
    "        \n",
    "        assert(num_items == len(ds))\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# Dataloading utilities from preprocessed HDF5 files.\n",
    "#\n",
    "# Copyright (C) 2019-2020 Robert Grupp (grupp@jhu.edu)\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program. If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import h5py as h5\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "\n",
    "# from util import *\n",
    "            \n",
    "def calc_pad_amount(padded_img_dim, cur_img_dim):\n",
    "    # new pad dimension should be larger\n",
    "    assert(padded_img_dim > cur_img_dim)\n",
    "\n",
    "    # first calculate the amount to pad along the borders\n",
    "    pad = (padded_img_dim - cur_img_dim)/ 2\n",
    "\n",
    "    # handle odd sized input\n",
    "    if pad != int(pad):\n",
    "        pad = int(pad) + 1\n",
    "    else:\n",
    "        # needs to be integral\n",
    "        pad = int(pad)\n",
    "\n",
    "    return pad\n",
    "\n",
    "class RandomDataAugDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, projs, segs, lands=None, proj_pad_dim=0):\n",
    "        self.projs = projs\n",
    "        self.segs  = segs\n",
    "        self.lands = lands\n",
    "   \n",
    "        assert(len(projs.shape) == 4)\n",
    "        assert(projs.shape[1] == 1)\n",
    "\n",
    "        if segs is not None:\n",
    "            assert(len(projs.shape) == len(segs.shape))\n",
    "            assert(projs.shape[0] == segs.shape[0])\n",
    "            \n",
    "            # initial sizes before padding should be equal\n",
    "            assert(projs.shape[2] == segs.shape[2])\n",
    "            assert(projs.shape[3] == segs.shape[3])\n",
    "        \n",
    "        if lands is not None:\n",
    "            assert(projs.shape[0] == lands.shape[0])\n",
    "            assert(lands.shape[1] == 2)\n",
    "\n",
    "        self.prob_of_aug = 0.5\n",
    "        #self.prob_of_aug = 1.0\n",
    "\n",
    "        self.do_invert = True\n",
    "        self.do_gamma  = True\n",
    "        self.do_noise  = True\n",
    "        self.do_affine = True\n",
    "        self.do_erase  = True\n",
    "\n",
    "        self.erase_prob = 0.25\n",
    "\n",
    "        self.pad_data_for_affine = True\n",
    "\n",
    "        self.do_norm_01_scale = True\n",
    "\n",
    "        self.include_heat_map = True\n",
    "\n",
    "        self.print_aug_info = False\n",
    "\n",
    "        self.extra_pad = 0\n",
    "        if proj_pad_dim > 0:\n",
    "            # only support square images for now\n",
    "            assert(projs.shape[-1] == projs.shape[-2])\n",
    "            self.extra_pad = calc_pad_amount(proj_pad_dim, projs.shape[-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.projs.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        assert(type(i) is int)\n",
    "\n",
    "        p = self.projs[i,:,:,:]\n",
    "\n",
    "        s = None\n",
    "        if self.segs is not None:\n",
    "            s = self.segs[i,:,:,:]\n",
    "\n",
    "        cur_lands = None\n",
    "        if self.lands is not None:\n",
    "            # we need a deep copy here because of possible data aug\n",
    "            cur_lands = self.lands[i,:,:].clone()\n",
    "\n",
    "        need_to_pad_proj = self.extra_pad > 0\n",
    "\n",
    "        if (self.prob_of_aug > 0) and (random.random() < self.prob_of_aug): \n",
    "            #print('augmenting...')\n",
    "\n",
    "            if self.do_invert and (random.random() < 0.5):\n",
    "                #print('  inversion...')\n",
    "\n",
    "                p_max = p.max()\n",
    "                #p_min = p.min()\n",
    "                p = p_max - p\n",
    "\n",
    "                if self.print_aug_info:\n",
    "                    print('inverting')\n",
    "\n",
    "            if self.do_noise:\n",
    "                # normalize to [0,1] to apply noise\n",
    "                p_min = p.min()\n",
    "                p_max = p.max()\n",
    "\n",
    "                p = (p - p_min) / (p_max - p_min)\n",
    "\n",
    "                cur_noise_sigma = random.uniform(0.005, 0.01)\n",
    "                p += torch.randn(p.shape) * cur_noise_sigma\n",
    "                \n",
    "                p = (p * (p_max - p_min)) + p_min\n",
    "\n",
    "                if self.print_aug_info:\n",
    "                    print('noise sigma: {:.3f}'.format(cur_noise_sigma))\n",
    "\n",
    "            if self.do_gamma:\n",
    "                # normalize to [0,1] to apply gamma\n",
    "                p_min = p.min()\n",
    "                p_max = p.max()\n",
    "\n",
    "                p = (p - p_min) / (p_max - p_min)\n",
    "\n",
    "                gamma = random.uniform(0.7,1.3)\n",
    "                p.pow_(gamma)\n",
    "\n",
    "                p = (p * (p_max - p_min)) + p_min\n",
    "\n",
    "                if self.print_aug_info:\n",
    "                    print('gamma = {:.2f}'.format(gamma))\n",
    "       \n",
    "            if self.do_affine:\n",
    "                # data needs to be in [0,1] for PIL functions\n",
    "                p_min = p.min()\n",
    "                p_max = p.max()\n",
    "\n",
    "                p = (p - p_min) / (p_max - p_min)\n",
    "                \n",
    "                orig_p_shape = p.shape\n",
    "                if self.pad_data_for_affine:\n",
    "                    pad1 = int(math.ceil(orig_p_shape[1] / 2.0))\n",
    "                    pad2 = int(math.ceil(orig_p_shape[2] / 2.0))\n",
    "                    if need_to_pad_proj:\n",
    "                        pad1 += self.extra_pad\n",
    "                        pad2 += self.extra_pad\n",
    "                        need_to_pad_proj = False\n",
    "\n",
    "                    p = torch.from_numpy(np.pad(p.numpy(),\n",
    "                                                ((0,0), (pad1,pad1), (pad2,pad2)),\n",
    "                                                'reflect'))\n",
    "                \n",
    "                p_il = TF.to_pil_image(p)\n",
    "\n",
    "                # this uniformly samples the direction\n",
    "                rand_trans = torch.randn(2)\n",
    "                rand_trans /= rand_trans.norm()\n",
    "\n",
    "                # now uniformly sample the magnitdue\n",
    "                rand_trans *= random.random() * 20\n",
    "                \n",
    "                rot_ang = random.uniform(-5, 5)\n",
    "                trans_x = rand_trans[0]\n",
    "                trans_y = rand_trans[1]\n",
    "                shear_x   = random.uniform(-2, 2)\n",
    "                shear_y   = random.uniform(-2, 2)\n",
    "                shear   = [shear_x,shear_x]\n",
    "                \n",
    "                scale_factor = random.uniform(0.9, 1.1)\n",
    "\n",
    "                if self.print_aug_info:\n",
    "                    print('Rot: {:.2f}'.format(rot_ang))\n",
    "                    print('Trans X: {:.2f} , Trans Y: {:.2f}'.format(trans_x, trans_y))\n",
    "                    print('Shear X: {:.2f},  Shaer Y: {:.2f}'.format(shear_x,shear_y))\n",
    "                    print('Scale: {:.2f}'.format(scale_factor))\n",
    "\n",
    "                p = TF.to_tensor(TF.affine(TF.to_pil_image(p),\n",
    "                                 rot_ang,\n",
    "                                 (trans_x, trans_y),\n",
    "                                 scale_factor,\n",
    "                                 shear,\n",
    "                                 resample=PIL.Image.BILINEAR))\n",
    "                \n",
    "                if self.pad_data_for_affine:\n",
    "                    # pad can be zero\n",
    "                    pad_shape = (orig_p_shape[-2] + (2 * self.extra_pad), orig_p_shape[-1] + (2 * self.extra_pad))\n",
    "                    p = center_crop(p, pad_shape)\n",
    "\n",
    "                p = (p * (p_max - p_min)) + p_min\n",
    "\n",
    "                if s is not None:\n",
    "                    orig_s_shape = s.shape\n",
    "                    if self.pad_data_for_affine:\n",
    "                        pad1 = int(math.ceil(orig_s_shape[1] / 2.0))\n",
    "                        pad2 = int(math.ceil(orig_s_shape[2] / 2.0))\n",
    "                        s = torch.from_numpy(np.pad(s.numpy(),\n",
    "                                                    ((0,0), (pad1,pad1), (pad2,pad2)),\n",
    "                                                    'reflect'))\n",
    "                    \n",
    "                    # warp each class separately, I don't want any wacky color\n",
    "                    # spaces assumed by PIL\n",
    "                    for c in range(s.shape[0]):\n",
    "                        s[c,:,:] = TF.to_tensor(TF.affine(TF.to_pil_image(s[c,:,:]),\n",
    "                                                          rot_ang,\n",
    "                                                          (trans_x, trans_y),\n",
    "                                                          scale_factor,\n",
    "                                                          shear))\n",
    "                    if self.pad_data_for_affine:\n",
    "                        s = center_crop(s, orig_s_shape)\n",
    "                \n",
    "                if cur_lands is not None:\n",
    "                    shape_for_center_of_rot = s.shape if s is not None else p.shape\n",
    "\n",
    "                    center_of_rot = ((shape_for_center_of_rot[-2] / 2.0) + 0.5,\n",
    "                                     (shape_for_center_of_rot[-1] / 2.0) + 0.5)\n",
    "                    \n",
    "                    A_inv = TF._get_inverse_affine_matrix(center_of_rot, rot_ang, (trans_x, trans_y), scale_factor, shear)\n",
    "                    A = np.matrix([ [A_inv[0], A_inv[1], A_inv[2]], [A_inv[3], A_inv[4], A_inv[5]], [0,0,1]]).I\n",
    "\n",
    "                    for pt_idx in range(cur_lands.shape[-1]):\n",
    "                        cur_land = cur_lands[:,pt_idx]\n",
    "                        if (not math.isinf(cur_land[0])) and (not math.isinf(cur_land[1])):\n",
    "                            tmp_pt = A * np.asmatrix(np.pad(cur_land.numpy(), (0,1), mode='constant', constant_values=1).reshape(3,1))\n",
    "                            xform_l = torch.from_numpy(np.squeeze(np.asarray(tmp_pt))[0:2])\n",
    "                            if (s is not None) and \\\n",
    "                               ((xform_l[0] < 0) or (xform_l[0] > (orig_s_shape[1] - 1)) or \\\n",
    "                                (xform_l[1] < 0) or (xform_l[1] < (orig_s_shape[0] - 1))):\n",
    "                                xform_l[0] = math.inf\n",
    "                                xform_l[1] = math.inf\n",
    "                            \n",
    "                            cur_lands[:,pt_idx] = xform_l\n",
    "            \n",
    "            if self.do_erase and (random.random() < self.erase_prob):\n",
    "                #print('  box noise/erase...')\n",
    "\n",
    "                p_2d_shape = [p.shape[-2], p.shape[-1]]\n",
    "                box_mean_dim = torch.Tensor([p_2d_shape[0] * 0.15, p_2d_shape[1] * 0.15])\n",
    "                \n",
    "                num_boxes = random.randint(1,5)\n",
    "                \n",
    "                if self.print_aug_info:\n",
    "                    print('  Random Corrupt: num. boxes: {}'.format(num_boxes))\n",
    "                \n",
    "                for box_idx in range(num_boxes):\n",
    "                    box_valid = False\n",
    "                    \n",
    "                    while not box_valid:\n",
    "                        # First sample box dims\n",
    "                        box_dims = torch.round((torch.randn(2) * (box_mean_dim)) + box_mean_dim).long()\n",
    "\n",
    "                        if (box_dims[0] > 0) and (box_dims[1] > 0) and \\\n",
    "                                (box_dims[0] <= p_2d_shape[0]) and (box_dims[1] <= p_2d_shape[1]):\n",
    "                            # Next sample box location\n",
    "                            start_row = random.randint(0, p_2d_shape[0] - box_dims[0])\n",
    "                            start_col = random.randint(0, p_2d_shape[1] - box_dims[1])\n",
    "\n",
    "                            box_valid = True\n",
    "                    \n",
    "                    p_roi = p[0,start_row:(start_row+box_dims[0]),start_col:(start_col+box_dims[1])]\n",
    "\n",
    "                    sigma_noise = (p_roi.max() - p_roi.min()) * 0.2\n",
    "                    \n",
    "                    p_roi += torch.randn(p_roi.shape) * sigma_noise\n",
    "\n",
    "        # end data aug\n",
    "\n",
    "        if need_to_pad_proj:\n",
    "            p = torch.from_numpy(np.pad(p.numpy(),\n",
    "                                 ((0, 0), (self.extra_pad, self.extra_pad), (self.extra_pad, self.extra_pad)),\n",
    "                                 'reflect'))\n",
    "\n",
    "        if self.do_norm_01_scale:\n",
    "            p = (p - p.mean()) / p.std()\n",
    "\n",
    "        h = None\n",
    "        if self.include_heat_map:\n",
    "            assert(s is not None)\n",
    "            assert(cur_lands is not None)\n",
    "\n",
    "            num_lands = cur_lands.shape[-1]\n",
    "\n",
    "            h = torch.zeros(num_lands, 1, s.shape[-2], s.shape[-1])\n",
    "\n",
    "            # \"FH-l\", \"FH-r\", \"GSN-l\", \"GSN-r\", \"IOF-l\", \"IOF-r\", \"MOF-l\", \"MOF-r\", \"SPS-l\", \"SPS-r\", \"IPS-l\", \"IPS-r\"\n",
    "            #sigma_lut = [ 2.5, 2.5, 7.5, 7.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5]\n",
    "            sigma_lut = torch.full([num_lands], 2.5)\n",
    "\n",
    "            (Y,X) = torch.meshgrid(torch.arange(0, s.shape[-2]),\n",
    "                                   torch.arange(0, s.shape[-1]))\n",
    "            Y = Y.float()\n",
    "            X = X.float()\n",
    "\n",
    "            for land_idx in range(num_lands):\n",
    "                sigma = sigma_lut[land_idx]\n",
    "\n",
    "                cur_land = cur_lands[:,land_idx]\n",
    "\n",
    "                mu_x = cur_land[0]\n",
    "                mu_y = cur_land[1]\n",
    "\n",
    "                if not math.isinf(mu_x) and not math.isinf(mu_y):\n",
    "                    pdf = torch.exp(((X - mu_x).pow(2) + (Y - mu_y).pow(2)) / (sigma * sigma * -2)) / (2 * math.pi * sigma * sigma)\n",
    "                    #pdf /= pdf.sum() # normalize to sum of 1\n",
    "                    h[land_idx,0,:,:] = pdf\n",
    "            #assert(torch.all(torch.isfinite(h)))\n",
    "\n",
    "        return (p,s,cur_lands,h)\n",
    "\n",
    "def get_orig_img_shape(h5_file_path, pat_ind):\n",
    "    f = h5.File(h5_file_path, 'r')\n",
    "        \n",
    "    s = f['{:02d}/projs'.format(pat_ind)].shape\n",
    "    \n",
    "    assert(len(s) == 3)\n",
    "    \n",
    "    return (s[1], s[2])\n",
    "\n",
    "def get_num_lands_from_dataset(h5_file_path):\n",
    "    f = h5.File(h5_file_path, 'r')\n",
    "    \n",
    "    num_lands = int(f['land-names/num-lands'][()])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return num_lands\n",
    "\n",
    "def get_land_names_from_dataset(h5_file_path):\n",
    "    f = h5.File(h5_file_path, 'r')\n",
    "    \n",
    "    num_lands = int(f['land-names/num-lands'][()])\n",
    "\n",
    "    land_names = []\n",
    "\n",
    "    for l in range(num_lands):\n",
    "        s = f['land-names/land-{:02d}'.format(l)][()]\n",
    "        if (type(s) is bytes) or (type(s) is np.bytes_):\n",
    "            s = s.decode()\n",
    "        assert(type(s) is str)\n",
    "\n",
    "        land_names.append(s)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "    return land_names\n",
    "\n",
    "\n",
    "def get_dataset(h5_file_path, pat_inds, num_classes,\n",
    "                pad_img_dim=0, no_seg=False,\n",
    "                minmax=None,\n",
    "                data_aug=False,\n",
    "                train_valid_split=None,\n",
    "                train_valid_idx=None,\n",
    "                dup_data_w_left_right_flip=False):\n",
    "    # classes:\n",
    "    # 0 --> BG\n",
    "    # 1 --> Pelvis\n",
    "    # 2 --> Left Femur\n",
    "    # 3 --> Right Femur\n",
    "        \n",
    "    need_to_scale_data   = False\n",
    "    need_to_find_min_max = False\n",
    "\n",
    "    if minmax is not None:\n",
    "        if (type(minmax) is bool) and minmax:\n",
    "            need_to_scale_data = True\n",
    "            print('need to find min/max for preprocessing...')\n",
    "            need_to_find_min_max = True\n",
    "            minmax_min =  math.inf\n",
    "            minmax_max = -math.inf\n",
    "        elif type(minmax) is tuple:\n",
    "            minmax_min = minmax[0]\n",
    "            minmax_max = minmax[1]\n",
    "            need_to_scale_data = True\n",
    "            print('using provided min/max for preprocessing: ({}, {})'.format(minmax_min, minmax_max))\n",
    "\n",
    "    f = h5.File(h5_file_path, 'r')\n",
    "\n",
    "    all_projs = None\n",
    "    all_segs  = None\n",
    "    all_lands = None\n",
    "\n",
    "    orig_img_shape = None\n",
    "\n",
    "    for pat_idx in pat_inds:\n",
    "        pat_g = f['{:02d}'.format(pat_idx)]\n",
    "\n",
    "        cur_projs_np = pat_g['projs'][:]\n",
    "        assert(len(cur_projs_np.shape) == 3)\n",
    "        print(f\"cur_projs_np shape={cur_projs_np.shape}\")\n",
    "\n",
    "        if orig_img_shape is None:\n",
    "            orig_img_shape = (cur_projs_np.shape[1], cur_projs_np.shape[2])#180*180\n",
    "        else:\n",
    "            assert(orig_img_shape[0] == cur_projs_np.shape[1])\n",
    "            assert(orig_img_shape[1] == cur_projs_np.shape[2])\n",
    "        \n",
    "        cur_lands = torch.from_numpy(pat_g['lands'][:])\n",
    "        assert(cur_lands.shape[0] == cur_projs_np.shape[0])\n",
    "        assert(torch.all(torch.isfinite(cur_lands)))  # all inputs should be finite\n",
    "\n",
    "        print(f\"cur_lands shape={cur_lands.shape}\")#Size([111, 2, 14])\n",
    "        print(f\"orig_img_shape shape=({orig_img_shape[0]},{orig_img_shape[1]})\")\n",
    "\n",
    "        # mark out of bounds landmarks with inf's\n",
    "        #不合法的数据直接设为math.inf\n",
    "        for img_idx in range(cur_lands.shape[0]):\n",
    "            for l_idx in range(cur_lands.shape[-1]):\n",
    "                cur_l = cur_lands[img_idx,:,l_idx]\n",
    "\n",
    "                if (cur_l[0] < 0) or (cur_l[0] > (orig_img_shape[1]-1)) or \\\n",
    "                   (cur_l[1] < 0) or (cur_l[1] > (orig_img_shape[0]-1)):\n",
    "                       cur_l[0] = math.inf\n",
    "                       cur_l[1] = math.inf\n",
    "\n",
    "        if need_to_find_min_max:\n",
    "            minmax_min = min(minmax_min, cur_projs_np.min())\n",
    "            minmax_max = max(minmax_max, cur_projs_np.max())\n",
    "\n",
    "        cur_projs = torch.from_numpy(cur_projs_np)\n",
    "        print(f\"cur_projs shape={cur_projs.shape}\")#[111, 180, 180]\n",
    "\n",
    "        # Need a singleton dimension to represent grayscale data\n",
    "        cur_projs = cur_projs.view(cur_projs.shape[0], 1, cur_projs.shape[1], cur_projs.shape[2])\n",
    "        print(f\"cur_projs shape={cur_projs.shape}\")#([111, 1, 180, 180])\n",
    "\n",
    "        if all_projs is None:\n",
    "            all_projs = cur_projs\n",
    "        else:\n",
    "            all_projs = torch.cat((all_projs, cur_projs))\n",
    "\n",
    "        cur_segs = torch.from_numpy(pat_g['segs'][:])\n",
    "        assert(len(cur_segs.shape) == 3)\n",
    "        print(f\"cur_segs shape={cur_segs.shape}\")#111, 180, 180\n",
    "        print(f\"all_projs shape={all_projs.shape}\")#111, 1, 180, 180\n",
    "\n",
    "        cur_segs_dice = torch.zeros(cur_segs.shape[0], num_classes, cur_segs.shape[1], cur_segs.shape[2])\n",
    "        print(f\"cur_segs_dice shape={cur_segs_dice.shape}\")#[111, 7, 180, 180]\n",
    "        \n",
    "        #设置dice [True,False]\n",
    "        for i in range(cur_segs.shape[0]):\n",
    "            for c in range(num_classes):\n",
    "                cur_segs_dice[i,c,:,:] = cur_segs[i,:,:] == c\n",
    "\n",
    "        if all_segs is None:\n",
    "            all_segs = cur_segs_dice.clone().detach()\n",
    "        else:\n",
    "            all_segs = torch.cat((all_segs, cur_segs_dice))\n",
    "\n",
    "        print(f\"all_segs shape={all_segs.shape}\")\n",
    "\n",
    "        if all_lands is None:\n",
    "            all_lands = cur_lands.clone().detach()\n",
    "        else:\n",
    "            all_lands = torch.cat((all_lands, cur_lands))\n",
    "\n",
    "        if dup_data_w_left_right_flip:#默认是Fasle\n",
    "            all_projs = torch.cat((all_projs, torch.flip(cur_projs, [3])))\n",
    "\n",
    "            # left/right flip the segmentations\n",
    "            cur_segs_dice = torch.flip(cur_segs_dice, [3])\n",
    "\n",
    "            assert(cur_segs_dice.shape[1] == 7)  # TODO: allow for a mapping to be passed\n",
    "            # update l/r labels\n",
    "            # 0 BG stays the same\n",
    "            # 1 left hemipelvis <--> 2 right hemipelvis\n",
    "            # 3 vertebrae stays the same\n",
    "            # 4 upper sacrum stays the smae\n",
    "            # 5 left femur <--> 6 left femur\n",
    "\n",
    "            def swap_classes(c1, c2):\n",
    "                tmp_copy  = cur_segs_dice[:,c1,:,:].clone().detach()\n",
    "                cur_segs_dice[:,c1,:,:] = cur_segs_dice[:,c2,:,:]\n",
    "                cur_segs_dice[:,c2,:,:] = tmp_copy\n",
    "\n",
    "            swap_classes(1,2)\n",
    "            swap_classes(5,6)\n",
    "\n",
    "            # flip lands and update, etc\n",
    "            for img_idx in range(cur_lands.shape[0]):\n",
    "                # do the l/r flip for each landmark\n",
    "                for l_idx in range(cur_lands.shape[-1]):\n",
    "                    cur_l = cur_lands[img_idx,:,l_idx]\n",
    "                    if math.isfinite(cur_l[0]) and math.isfinite(cur_l[1]):\n",
    "                        cur_l[0] = (orig_img_shape[-1] - 1) - cur_l[0]\n",
    "                \n",
    "                # now swap the l/r landmarks\n",
    "                assert((cur_lands.shape[-1] % 2) == 0)\n",
    "                for l_idx in range(cur_lands.shape[-1] // 2):\n",
    "                    tmp_land = cur_lands[img_idx,:,l_idx].clone().detach()\n",
    "                    cur_lands[img_idx,:,l_idx] = cur_lands[img_idx,:,l_idx+1]\n",
    "                    cur_lands[img_idx,:,l_idx] = tmp_land\n",
    "            \n",
    "            all_segs = torch.cat((all_segs, cur_segs_dice))\n",
    "            all_lands = torch.cat((all_lands, cur_lands))\n",
    "    \n",
    "    # end loop over patients\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    # scale to [0,1] if needed\n",
    "    if need_to_scale_data:\n",
    "        assert((minmax_max - minmax_min) > 1.0e-6)\n",
    "        print('scaling data using min/max: {} , {}'.format(minmax_min, minmax_max))\n",
    "        all_projs = (all_projs - minmax_min) / (minmax_max - minmax_min)\n",
    "    \n",
    "    def set_helper_vars(ds, do_data_aug):\n",
    "        ds.prob_of_aug = 0.5 if do_data_aug else 0.0\n",
    "        \n",
    "        # stuff in some custom vars\n",
    "        ds.rob_orig_img_shape = orig_img_shape\n",
    "\n",
    "        ds.rob_data_is_scaled = need_to_scale_data\n",
    "        if need_to_scale_data:\n",
    "            ds.rob_minmax = (minmax_min, minmax_max)\n",
    "\n",
    "    if (train_valid_split is not None) and (train_valid_split > 0):\n",
    "        print('split dataset into train/validation')\n",
    "        assert((0.0 < train_valid_split) and (train_valid_split < 1.0))\n",
    "        num_train = int(math.ceil(train_valid_split * all_projs.shape[0]))\n",
    "        num_valid = all_projs.shape[0] - num_train\n",
    "\n",
    "        all_inds = list(range(all_projs.shape[0]))\n",
    "        \n",
    "        if (train_valid_idx is None) or (train_valid_idx[0] is None) or (train_valid_idx[1] is None):\n",
    "            print('  randomly splitting all complete tensors into training/validation...')\n",
    "            random.shuffle(all_inds)\n",
    "\n",
    "            train_inds = all_inds[:num_train]\n",
    "            valid_inds = all_inds[num_train:]\n",
    "        else:\n",
    "            print('  use previously specified split')\n",
    "            train_inds = train_valid_idx[0]\n",
    "            valid_inds = train_valid_idx[1]\n",
    "            assert(len(train_inds) == num_train)\n",
    "            assert(len(valid_inds) == num_valid)\n",
    "        \n",
    "        train_ds = RandomDataAugDataSet(all_projs[train_inds,:,:,:], all_segs[train_inds,:,:,:], all_lands[train_inds,:,:], proj_pad_dim=pad_img_dim)\n",
    "        set_helper_vars(train_ds, data_aug)\n",
    "        \n",
    "        valid_ds = RandomDataAugDataSet(all_projs[valid_inds,:,:,:], all_segs[valid_inds,:,:,:], all_lands[valid_inds,:,:], proj_pad_dim=pad_img_dim)\n",
    "        set_helper_vars(valid_ds, False)\n",
    "\n",
    "        return (train_ds, valid_ds, train_inds, valid_inds)\n",
    "    else:\n",
    "        ds = RandomDataAugDataSet(all_projs, all_segs, all_lands, proj_pad_dim=pad_img_dim)\n",
    "        set_helper_vars(ds, data_aug)\n",
    "\n",
    "        return ds\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the data "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "#Log transform\n",
    "def ogarithmic_transformation(input_image:np.ndarray, c=1, inplace = True):\n",
    "    '''\n",
    "    对数变换\n",
    "    :param input_image: 原图像\n",
    "    :param c: 对数变换超参数\n",
    "    :return: 对数变换后的图像\n",
    "    '''\n",
    "    # input_image_np = np.copy(input_image)\n",
    "    input_image_cp = input_image\n",
    "    if not inplace:\n",
    "        input_image_cp = input_image.copy()\n",
    "        \n",
    "    output_imgae = c * np.log(1 + input_image_cp) # 输出图像\n",
    "\n",
    "    return output_imgae"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "def prepare_data(cur_proj_np:np.ndarray):\n",
    "    \n",
    "    #1.剪裁\n",
    "    cur_proj_np = cur_proj_np[50:-50,50:-50]\n",
    "\n",
    "    # 2.下采样\n",
    "    # Since the projections are 1536x1536, a tiled image of ~100 projections\n",
    "    # may be excessively large, downsample in this case\n",
    "    #overlay_ds_factor = 1.0   # no downsampling\n",
    "    overlay_ds_factor = 0.125 # downsample 8x in each 2D dim\n",
    "\n",
    "    need_to_ds_overlay = abs(overlay_ds_factor - 1.0) > 0.001\n",
    "\n",
    "    (proj_num_cols,proj_num_rows) = cur_proj_np.shape\n",
    "\n",
    "    # downsampled overlay dimensions\n",
    "    ds_proj_num_cols = int(round(proj_num_cols * overlay_ds_factor)) if need_to_ds_overlay else proj_num_cols\n",
    "    ds_proj_num_rows = int(round(proj_num_rows * overlay_ds_factor)) if need_to_ds_overlay else proj_num_rows\n",
    "\n",
    "    pil = TF.to_pil_image(cur_proj_np)\n",
    "    if need_to_ds_overlay:\n",
    "        pil = pil.resize((ds_proj_num_cols, ds_proj_num_rows), Image.BILINEAR)\n",
    "        # cur_proj = TF.to_tensor(pil)\n",
    "        # print(f\"cur_proj shape:{cur_proj.shape}\")\n",
    "    # else:\n",
    "    cur_proj_np = np.array(pil)\n",
    "    print(f\"cur dtype:{cur_proj_np.dtype}\")\n",
    "    # #show\n",
    "    # plt.imshow(pil,cmap='gray')\n",
    "    # plt.show()\n",
    "    \n",
    "    #3.log transform\n",
    "    cur_proj_np = ogarithmic_transformation(cur_proj_np,1)\n",
    "    #cur_proj = torch.log(1+cur_proj)\n",
    "  \n",
    "\n",
    "    #数据需要归一化\n",
    "    #找出最小值\n",
    "    # minmax_min =  math.inf\n",
    "    # minmax_max = -math.inf\n",
    "    # minmax_min = min(minmax_min, cur_proj_np.min())\n",
    "    # minmax_max = max(minmax_max, cur_proj_np.max())\n",
    "    # print(f\"max:{minmax_max},min:{minmax_min}\")\n",
    "    \n",
    "    \n",
    "    # #归一化操作\n",
    "    # assert((minmax_max - minmax_min) > 1.0e-6)\n",
    "    # print('scaling data using min/max: {} , {}'.format(minmax_min, minmax_max))\n",
    "    # cur_proj_np = (cur_proj_np - minmax_min) / (minmax_max - minmax_min)\n",
    "\n",
    "\n",
    "    #4.pading 到192x192\n",
    "    cur_proj = torch.from_numpy(np.pad(cur_proj_np,\n",
    "                                 ( (6,6), (6,6)),\n",
    "                                 'reflect'))\n",
    "    # cur_proj = TF.pad(cur_proj,(0,6,6),0,'reflect')\n",
    "    cur_proj = (cur_proj - cur_proj.mean()) / cur_proj.std()\n",
    "\n",
    "    x = torch.unsqueeze(cur_proj,0)\n",
    "    x = torch.unsqueeze(x,0).type(torch.FloatTensor)  # 转Float\n",
    "    print(f\"cur_proj shape:{x.shape}\\n cur_proj dtype:{x.dtype}\")\n",
    "\n",
    "    do_invert = True\n",
    "    do_gamma  = True\n",
    "    do_noise  = True\n",
    "    do_affine = True\n",
    "    do_erase  = True\n",
    "\n",
    "\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 单个数据的推断"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "def seg_single_data_ensemble(data,net,h5_f,dev=None,num_lands=0):\n",
    "     \n",
    "    orig_img_shape = (180,180)\n",
    "\n",
    "    dst_ds = h5_f.create_dataset('nn-segs', (1, *orig_img_shape),\n",
    "                                 dtype='u1',\n",
    "                                 chunks=(1, *orig_img_shape),\n",
    "                                 compression=\"gzip\", compression_opts=9)\n",
    "    if num_lands > 0:\n",
    "        dst_heats_ds = h5_f.create_dataset('nn-heats', (1, num_lands, *orig_img_shape),\n",
    "                                        chunks=(1,1,*orig_img_shape),\n",
    "                                        compression=\"gzip\", compression_opts=9)  \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        input = data.to(dev)\n",
    "        net_out = net(input)\n",
    "        if (num_lands > 0) or (type(net_out) is tuple):\n",
    "            pred_masks = net_out[0]\n",
    "            pred_heats = net_out[1]  \n",
    "        else:\n",
    "            pred_masks = net_out\n",
    "\n",
    "        pred_masks = center_crop(pred_masks, orig_img_shape)\n",
    "\n",
    "        if dst_heats_ds is not None:\n",
    "            pred_heats = center_crop(pred_heats, orig_img_shape)\n",
    "            \n",
    "            pred_heats_min = pred_heats.min().item()\n",
    "            pred_heats_max = pred_heats.max().item()\n",
    "            \n",
    "            pred_heats = (pred_heats - pred_heats_min) / (pred_heats_max - pred_heats_min)\n",
    "\n",
    "\n",
    "        (_, pred_masks) = torch.max(pred_masks, dim=1) \n",
    "\n",
    "        # write to file\n",
    "        dst_ds[0,:,:] = pred_masks.view(orig_img_shape).cpu().numpy()\n",
    "        dst_heats_ds[0,:,:,:] = pred_heats.cpu().numpy()                   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "from unet    import *\n",
    "#python -u test_ensemble.py ipcai_2020_ds_8x.h5 spec_1_test.h5 --pats 1 --nets yy_best_net.pt\n",
    "# os.path.pardir('')\n",
    "torch_map_loc = None\n",
    "network_paths=list()\n",
    "\n",
    "network_paths.append(os.path.join(cur_path,'yy_best_net.pt'))  \n",
    "print(network_paths)\n",
    "\n",
    "cpu_dev = torch.device('cpu')\n",
    "dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch_map_loc = dev\n",
    "print(f\"dev type:{dev}\")\n",
    "\n",
    "nets=[]\n",
    "for net_path in network_paths:\n",
    "        print('  loading state from disk for: {}'.format(net_path))\n",
    "        \n",
    "        state = torch.load(net_path, map_location=torch_map_loc)\n",
    "        \n",
    "        print('  loading unet params from checkpoint state dict...')\n",
    "        num_classes         = state['num-classes']\n",
    "        unet_num_lvls       = state['depth']\n",
    "        unet_init_feats_exp = state['init-feats-exp']\n",
    "        unet_batch_norm     = state['batch-norm']\n",
    "        unet_padding        = state['padding']\n",
    "        unet_no_max_pool    = state['no-max-pool']\n",
    "        unet_use_res        = state['unet-use-res']\n",
    "        unet_block_depth    = state['unet-block-depth']\n",
    "        proj_unet_dim       = state['pad-img-size']\n",
    "        batch_size          = state['batch-size']\n",
    "        num_lands           = state['num-lands']\n",
    "        epoch               = state['epoch']\n",
    "        loss                = state['loss']\n",
    "        best_valid_loss     = state['best-valid-loss']\n",
    "\n",
    "        print('             num. classes: {}'.format(num_classes))\n",
    "        print('                    depth: {}'.format(unet_num_lvls))\n",
    "        print('        init. feats. exp.: {}'.format(unet_init_feats_exp))\n",
    "        print('              batch norm.: {}'.format(unet_batch_norm))\n",
    "        print('         unet do pad img.: {}'.format(unet_padding))\n",
    "        print('              no max pool: {}'.format(unet_no_max_pool))\n",
    "        print('    reflect pad img. dim.: {}'.format(proj_unet_dim))\n",
    "        print('            unet use res.: {}'.format(unet_use_res))\n",
    "        print('         unet block depth: {}'.format(unet_block_depth))\n",
    "        print('               batch size: {}'.format(batch_size))\n",
    "        print('              num. lands.: {}'.format(num_lands))\n",
    "        \n",
    "        print('          Last Epoch: {}'.format(epoch))\n",
    "        print('           Last Loss: {}'.format(loss.item()))\n",
    "        print('    Best Valid. Loss: {}'.format(best_valid_loss))\n",
    "\n",
    "        print('    creating network')\n",
    "        net = UNet(n_classes=num_classes, depth=unet_num_lvls, wf=unet_init_feats_exp, batch_norm=unet_batch_norm, padding=unet_padding, max_pool=not unet_no_max_pool,\n",
    "                   num_lands=num_lands, do_res=unet_use_res, block_depth=unet_block_depth)\n",
    "    \n",
    "        net.load_state_dict(state['model-state-dict'])\n",
    "\n",
    "        del state\n",
    "\n",
    "        print('  moving network to device...')\n",
    "        net.to(dev)\n",
    "        \n",
    "        nets.append(net)\n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['/home/xindong/project/rg2-work/yy_best_net.pt']\n",
      "dev type:cuda:0\n",
      "  loading state from disk for: /home/xindong/project/rg2-work/yy_best_net.pt\n",
      "  loading unet params from checkpoint state dict...\n",
      "             num. classes: 7\n",
      "                    depth: 6\n",
      "        init. feats. exp.: 5\n",
      "              batch norm.: True\n",
      "         unet do pad img.: True\n",
      "              no max pool: True\n",
      "    reflect pad img. dim.: 192\n",
      "            unet use res.: True\n",
      "         unet block depth: 2\n",
      "               batch size: 5\n",
      "              num. lands.: 14\n",
      "          Last Epoch: 484\n",
      "           Last Loss: -0.7985647916793823\n",
      "    Best Valid. Loss: -0.8046208620071411\n",
      "    creating network\n",
      "  moving network to device...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# src_data_file_path = os.path.join(data_path,'ipcai_2020_ds_8x.h5')\n",
    "src_data_file_path = os.path.join(data_path,'my_source_ds.h5')\n",
    "# dst_data_file_path = os.path.join(data_path,'spec_1_test_bxd.h5')\n",
    "dst_data_file_path = os.path.join(data_path,'spec_1_test_my_source5.h5')\n",
    "test_pats =[]\n",
    "test_pats.append(1)\n",
    "\n",
    "land_names = None\n",
    "if num_lands > 0:\n",
    "        land_names = get_land_names_from_dataset(src_data_file_path)\n",
    "        assert(len(land_names) == num_lands)\n",
    "\n",
    "# print('initializing testing dataset')\n",
    "# test_ds = get_dataset(src_data_file_path, test_pats, num_classes=num_classes,\n",
    "#                           pad_img_dim=proj_unet_dim, no_seg=True)\n",
    "\n",
    "print('initializing testing data')\n",
    "xray_data = prepare_data(xray_data) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "initializing testing data\n",
      "cur dtype:float32\n",
      "max:11.06914234161377,min:9.217945098876953\n",
      "scaling data using min/max: 9.217945098876953 , 11.06914234161377\n",
      "cur_proj shape:torch.Size([1, 1, 192, 192])\n",
      " cur_proj dtype:torch.float32\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "# print('Length of testing dataset: {}'.format(len(test_ds)))\n",
    "\n",
    "print('opening destination file for writing')\n",
    "f = h5.File(dst_data_file_path, 'w')\n",
    "\n",
    "# save off the landmark names\n",
    "if land_names:\n",
    "        land_names_g = f.create_group('land-names')\n",
    "        land_names_g['num-lands'] = num_lands\n",
    "\n",
    "for l in range(num_lands):\n",
    "        land_names_g['land-{:02d}'.format(l)] = land_names[l]\n",
    "\n",
    "times = []\n",
    "\n",
    "print('running network on projections')\n",
    "# seg_dataset_ensemble(test_ds, nets, f, dev=dev, num_lands=num_lands, times=times)\n",
    "\n",
    "seg_single_data_ensemble(xray_data,nets[0],f,dev=dev,num_lands=num_lands)\n",
    "\n",
    "print('closing file...')\n",
    "f.flush()\n",
    "f.close()\n",
    "\n",
    "test_time=''\n",
    "if test_time:\n",
    "        times_out = open(test_time, 'w')\n",
    "        for t in times:\n",
    "                times_out.write('{:.6f}\\n'.format(t))\n",
    "        times_out.flush()\n",
    "        times_out.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "opening destination file for writing\n",
      "running network on projections\n",
      "closing file...\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('monaienv': venv)"
  },
  "interpreter": {
   "hash": "41cc7d8094642f0aa3e27d256eb25d3485d313a694ac935cfb444781e1af4b99"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}